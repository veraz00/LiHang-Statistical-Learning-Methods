{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (150, 4)\n",
      "Length of labels:  150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'Iris-setosa': 50, 'Iris-versicolor': 50, 'Iris-virginica': 50})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(file):\n",
    "    Xlist, Ylist = [], []\n",
    "    fr = open(file)\n",
    "    for line in fr.readlines():\n",
    "        cur = line.strip().split(',')\n",
    "        label = cur[-1]\n",
    "        X = [float(x) for x in cur[:-1]]\n",
    "        Xlist.append(X)\n",
    "        Ylist.append(label)\n",
    "    Xarray = np.array(Xlist)\n",
    "    print('Data shape: ', Xarray.shape)\n",
    "    print('Length of labels: ', len(Ylist))\n",
    "    return Xarray, Ylist\n",
    "f1 = 'iris.data'\n",
    "Xarray, Ylist = load_data(f1)  # Counter({'Iris-setosa': 50, 'Iris-versicolor': 50, 'Iris-virginica': 50})\n",
    "from collections import Counter \n",
    "Counter(Ylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(Xarray):\n",
    "    for f in range(Xarray.shape[1]):\n",
    "        maxf = np.max(Xarray[:, f])\n",
    "        minf = np.min(Xarray[:, f])\n",
    "        for n in range(Xarray.shape[0]):\n",
    "            Xarray[n][f] = (Xarray[n][f]-minf)/(maxf-minf)\n",
    "    return Xarray\n",
    "Xarray = Normalize(Xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.21561354 0.16810102 ... 1.08257132 1.14907064 0.96462829]\n",
      " [0.21561354 0.         0.10157824 ... 1.08390691 1.17619813 0.95649502]\n",
      " [0.16810102 0.10157824 0.         ... 1.12088708 1.19544459 0.98859665]\n",
      " ...\n",
      " [1.08257132 1.08390691 1.12088708 ... 0.         0.226928   0.18710825]\n",
      " [1.14907064 1.17619813 1.19544459 ... 0.226928   0.         0.28409587]\n",
      " [0.96462829 0.95649502 0.98859665 ... 0.18710825 0.28409587 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def cal_distance(xi, xj):\n",
    "    dist = 0\n",
    "    for col in range(len(xi)):\n",
    "        dist += (xi[col]-xj[col])**2\n",
    "    dist = math.sqrt(dist)\n",
    "    return dist \n",
    "\n",
    "def Distances(Xarray):\n",
    "    '''\n",
    "    INPUT:\n",
    "    Xarray - (array) 特征数据数组\n",
    "    \n",
    "    OUTPUT:\n",
    "    dists - (array) 两两数据的欧式距离数组\n",
    "    \n",
    "    '''\n",
    "    dists = np.zeros((Xarray.shape[0], Xarray.shape[0]))\n",
    "    for n1 in range(Xarray.shape[0]):\n",
    "        for n2 in range(n1):\n",
    "            dists[n1][n2] = cal_distance(Xarray[n1], Xarray[n2])\n",
    "            dists[n2][n1] = dists[n1][n2]\n",
    "        dists[n1][n1] = 0\n",
    "    return dists\n",
    "\n",
    "dists = Distances(Xarray)\n",
    "print(dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of groups:  150\n",
      "number of groups:  151\n",
      "number of groups:  152\n",
      "number of groups:  153\n",
      "number of groups:  154\n",
      "number of groups:  155\n",
      "number of groups:  156\n",
      "number of groups:  157\n",
      "number of groups:  158\n",
      "number of groups:  159\n",
      "number of groups:  160\n",
      "number of groups:  161\n",
      "number of groups:  162\n",
      "number of groups:  163\n",
      "number of groups:  164\n",
      "number of groups:  165\n",
      "number of groups:  166\n",
      "number of groups:  167\n",
      "number of groups:  168\n",
      "number of groups:  169\n",
      "number of groups:  170\n",
      "number of groups:  171\n",
      "number of groups:  172\n",
      "number of groups:  173\n",
      "number of groups:  174\n",
      "number of groups:  175\n",
      "number of groups:  176\n",
      "number of groups:  177\n",
      "number of groups:  178\n",
      "number of groups:  179\n",
      "number of groups:  180\n",
      "number of groups:  181\n",
      "number of groups:  182\n",
      "number of groups:  183\n",
      "number of groups:  184\n",
      "number of groups:  185\n",
      "number of groups:  186\n",
      "number of groups:  187\n",
      "number of groups:  188\n",
      "number of groups:  189\n",
      "number of groups:  190\n",
      "number of groups:  191\n",
      "number of groups:  192\n",
      "number of groups:  193\n",
      "number of groups:  194\n",
      "number of groups:  195\n",
      "number of groups:  196\n",
      "number of groups:  197\n",
      "number of groups:  198\n",
      "number of groups:  199\n",
      "number of groups:  200\n",
      "number of groups:  201\n",
      "number of groups:  202\n",
      "number of groups:  203\n",
      "number of groups:  204\n",
      "number of groups:  205\n",
      "number of groups:  206\n",
      "number of groups:  207\n",
      "number of groups:  208\n",
      "number of groups:  209\n",
      "number of groups:  210\n",
      "number of groups:  211\n",
      "number of groups:  212\n",
      "number of groups:  213\n",
      "number of groups:  214\n",
      "number of groups:  215\n",
      "number of groups:  216\n",
      "number of groups:  217\n",
      "number of groups:  218\n",
      "number of groups:  219\n",
      "number of groups:  220\n",
      "number of groups:  221\n",
      "number of groups:  222\n",
      "number of groups:  223\n",
      "number of groups:  224\n",
      "number of groups:  225\n",
      "number of groups:  226\n",
      "number of groups:  227\n",
      "number of groups:  228\n",
      "number of groups:  229\n",
      "number of groups:  230\n",
      "number of groups:  231\n",
      "number of groups:  232\n",
      "number of groups:  233\n",
      "number of groups:  234\n",
      "number of groups:  235\n",
      "number of groups:  236\n",
      "number of groups:  237\n",
      "number of groups:  238\n",
      "number of groups:  239\n",
      "number of groups:  240\n",
      "number of groups:  241\n",
      "number of groups:  242\n",
      "number of groups:  243\n",
      "number of groups:  244\n",
      "number of groups:  245\n",
      "number of groups:  246\n",
      "number of groups:  247\n",
      "number of groups:  248\n",
      "number of groups:  249\n",
      "number of groups:  250\n",
      "number of groups:  251\n",
      "number of groups:  252\n",
      "number of groups:  253\n",
      "number of groups:  254\n",
      "number of groups:  255\n",
      "number of groups:  256\n",
      "number of groups:  257\n",
      "number of groups:  258\n",
      "number of groups:  259\n",
      "number of groups:  260\n",
      "number of groups:  261\n",
      "number of groups:  262\n",
      "number of groups:  263\n",
      "number of groups:  264\n",
      "number of groups:  265\n",
      "number of groups:  266\n",
      "number of groups:  267\n",
      "number of groups:  268\n",
      "number of groups:  269\n",
      "number of groups:  270\n",
      "number of groups:  271\n",
      "number of groups:  272\n",
      "number of groups:  273\n",
      "number of groups:  274\n",
      "number of groups:  275\n",
      "number of groups:  276\n",
      "number of groups:  277\n",
      "number of groups:  278\n",
      "number of groups:  279\n",
      "number of groups:  280\n",
      "number of groups:  281\n",
      "number of groups:  282\n",
      "number of groups:  283\n",
      "number of groups:  284\n",
      "number of groups:  285\n",
      "number of groups:  286\n",
      "number of groups:  287\n",
      "number of groups:  288\n",
      "number of groups:  289\n",
      "number of groups:  290\n",
      "number of groups:  291\n",
      "number of groups:  292\n",
      "number of groups:  293\n",
      "number of groups:  294\n",
      "number of groups:  295\n",
      "number of groups:  296\n",
      "group_dict {41: [41], 284: [33, 32, 14, 26, 23, 27, 0, 40, 17, 39, 7, 28, 49, 4, 35, 24, 11, 20, 6, 38, 8, 13, 47, 2, 29, 3, 30, 37, 34, 9, 25, 1, 45, 12, 42, 36, 46, 19, 21, 48, 10, 44, 31, 43, 16, 5, 18, 22, 15], 296: [143, 120, 140, 145, 141, 144, 139, 112, 124, 147, 110, 137, 116, 103, 132, 128, 104, 138, 127, 149, 70, 126, 123, 111, 146, 102, 86, 52, 75, 65, 58, 50, 97, 74, 71, 91, 63, 78, 61, 76, 73, 54, 84, 66, 56, 51, 85, 133, 83, 89, 53, 95, 88, 99, 96, 94, 55, 92, 82, 90, 81, 80, 69, 67, 79, 64, 77, 148, 136, 100, 115, 59, 134, 72, 142, 101, 121, 113, 87, 68, 119, 129, 125, 130, 107, 122, 105, 135, 108, 118, 93, 57, 98, 60, 62, 114, 109, 106, 131, 117]}\n"
     ]
    }
   ],
   "source": [
    "# Consolidation criteria: 最短距离 between 2 groups \n",
    "def cal_groupdist(g1, g2, group_dict, dists):\n",
    "    d = float('inf')\n",
    "    for xi in group_dict[g1]:\n",
    "        for xj in group_dict[g2]:\n",
    "            if xi != xj:\n",
    "                d = min(d, dists[xi][xj])\n",
    "    return d\n",
    "\n",
    "\n",
    "def clustersing(Xarray, k, dists):\n",
    "    '''\n",
    "    INPUT:\n",
    "    Xarray - (array) 特征数据数组\n",
    "    k - (int) 设定的类别数\n",
    "    dists - (array) 两两数据的欧式距离数组\n",
    "    \n",
    "    OUTPUT:\n",
    "    group_dict - (dict) 类别字典\n",
    "    '''\n",
    "    group_dict = dict()\n",
    "    for n in range(Xarray.shape[0]):\n",
    "        group_dict[n] = [n]\n",
    "    newgroup = Xarray.shape[0]\n",
    "    while len(group_dict.keys())> k:\n",
    "        group_dicts = dict()\n",
    "        for g1 in group_dict.keys():\n",
    "            for g2 in group_dict.keys():\n",
    "                if g1 != g2:\n",
    "                    if (g1, g2) not in group_dicts.values():\n",
    "                        d = cal_groupdist(g1, g2, group_dict, dists)\n",
    "                        group_dicts[d] = (g1, g2)\n",
    "        group_mindist = min(list(group_dicts.keys()))\n",
    "        mingroups = group_dicts[group_mindist]\n",
    "        new = []\n",
    "        for g in mingroups:\n",
    "            new.extend(group_dict[g])\n",
    "            del group_dict[g]\n",
    "            \n",
    "        group_dict[newgroup] = new\n",
    "        newgroup += 1\n",
    "    return group_dict\n",
    "k = 3\n",
    "group_dict = clustersing(Xarray, k, dists)\n",
    "print('group_dict', group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_dict {41: [41], 284: [33, 32, 14, 26, 23, 27, 0, 40, 17, 39, 7, 28, 49, 4, 35, 24, 11, 20, 6, 38, 8, 13, 47, 2, 29, 3, 30, 37, 34, 9, 25, 1, 45, 12, 42, 36, 46, 19, 21, 48, 10, 44, 31, 43, 16, 5, 18, 22, 15], 296: [143, 120, 140, 145, 141, 144, 139, 112, 124, 147, 110, 137, 116, 103, 132, 128, 104, 138, 127, 149, 70, 126, 123, 111, 146, 102, 86, 52, 75, 65, 58, 50, 97, 74, 71, 91, 63, 78, 61, 76, 73, 54, 84, 66, 56, 51, 85, 133, 83, 89, 53, 95, 88, 99, 96, 94, 55, 92, 82, 90, 81, 80, 69, 67, 79, 64, 77, 148, 136, 100, 115, 59, 134, 72, 142, 101, 121, 113, 87, 68, 119, 129, 125, 130, 107, 122, 105, 135, 108, 118, 93, 57, 98, 60, 62, 114, 109, 106, 131, 117]}\n"
     ]
    }
   ],
   "source": [
    "print('group_dict', group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "adjusted index:  0.5583714437541352\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def Adjusted_Rand_Index(group_dict, Ylist, k):\n",
    "    '''\n",
    "    INPUT:\n",
    "    group_dict - (dict) 类别字典\n",
    "    Ylist - (list) 类别标签列表\n",
    "    k - (int) 设定的类别数\n",
    "    \n",
    "    OUTPUT:\n",
    "    (int) 调整兰德系数\n",
    "    \n",
    "    '''\n",
    "    prediction_list = [0] * len(Ylist)\n",
    "    i = 0\n",
    "    for a in group_dict.keys():\n",
    "        for g in group_dict[a]:\n",
    "            prediction_list[g] = i\n",
    "        i += 1\n",
    "    y_list = [0] * len(Ylist)\n",
    "    for i in range(len(Ylist)): # Counter({'Iris-setosa': 50, 'Iris-versicolor': 50, 'Iris-virginica': 50})\n",
    "        if Ylist[i] == Ylist[52]:\n",
    "            y_list[i] = 1\n",
    "        elif Ylist[i] == Ylist[-1]:\n",
    "            y_list[i] = 2\n",
    "    print(prediction_list)\n",
    "    print(y_list)\n",
    "    result = metrics.adjusted_rand_score(y_list, prediction_list)\n",
    "#     >>> adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 1])\n",
    "# 1.0\n",
    "# >>> adjusted_rand_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
    "# 1.0\n",
    "    return result\n",
    "result = Adjusted_Rand_Index(group_dict, Ylist, 3)\n",
    "print('adjusted index: ', result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (150, 4)\n",
      "Length of labels:  150\n",
      "[[0.         0.21561354 0.16810102 ... 1.08257132 1.14907064 0.96462829]\n",
      " [0.21561354 0.         0.10157824 ... 1.08390691 1.17619813 0.95649502]\n",
      " [0.16810102 0.10157824 0.         ... 1.12088708 1.19544459 0.98859665]\n",
      " ...\n",
      " [1.08257132 1.08390691 1.12088708 ... 0.         0.226928   0.18710825]\n",
      " [1.14907064 1.17619813 1.19544459 ... 0.226928   0.         0.28409587]\n",
      " [0.96462829 0.95649502 0.98859665 ... 0.18710825 0.28409587 0.        ]]\n",
      "number of groups:  150\n",
      "number of groups:  151\n",
      "number of groups:  152\n",
      "number of groups:  153\n",
      "number of groups:  154\n",
      "number of groups:  155\n",
      "number of groups:  156\n",
      "number of groups:  157\n",
      "number of groups:  158\n",
      "number of groups:  159\n",
      "number of groups:  160\n",
      "number of groups:  161\n",
      "number of groups:  162\n",
      "number of groups:  163\n",
      "number of groups:  164\n",
      "number of groups:  165\n",
      "number of groups:  166\n",
      "number of groups:  167\n",
      "number of groups:  168\n",
      "number of groups:  169\n",
      "number of groups:  170\n",
      "number of groups:  171\n",
      "number of groups:  172\n",
      "number of groups:  173\n",
      "number of groups:  174\n",
      "number of groups:  175\n",
      "number of groups:  176\n",
      "number of groups:  177\n",
      "number of groups:  178\n",
      "number of groups:  179\n",
      "number of groups:  180\n",
      "number of groups:  181\n",
      "number of groups:  182\n",
      "number of groups:  183\n",
      "number of groups:  184\n",
      "number of groups:  185\n",
      "number of groups:  186\n",
      "number of groups:  187\n",
      "number of groups:  188\n",
      "number of groups:  189\n",
      "number of groups:  190\n",
      "number of groups:  191\n",
      "number of groups:  192\n",
      "number of groups:  193\n",
      "number of groups:  194\n",
      "number of groups:  195\n",
      "number of groups:  196\n",
      "number of groups:  197\n",
      "number of groups:  198\n",
      "number of groups:  199\n",
      "number of groups:  200\n",
      "number of groups:  201\n",
      "number of groups:  202\n",
      "number of groups:  203\n",
      "number of groups:  204\n",
      "number of groups:  205\n",
      "number of groups:  206\n",
      "number of groups:  207\n",
      "number of groups:  208\n",
      "number of groups:  209\n",
      "number of groups:  210\n",
      "number of groups:  211\n",
      "number of groups:  212\n",
      "number of groups:  213\n",
      "number of groups:  214\n",
      "number of groups:  215\n",
      "number of groups:  216\n",
      "number of groups:  217\n",
      "number of groups:  218\n",
      "number of groups:  219\n",
      "number of groups:  220\n",
      "number of groups:  221\n",
      "number of groups:  222\n",
      "number of groups:  223\n",
      "number of groups:  224\n",
      "number of groups:  225\n",
      "number of groups:  226\n",
      "number of groups:  227\n",
      "number of groups:  228\n",
      "number of groups:  229\n",
      "number of groups:  230\n",
      "number of groups:  231\n",
      "number of groups:  232\n",
      "number of groups:  233\n",
      "number of groups:  234\n",
      "number of groups:  235\n",
      "number of groups:  236\n",
      "number of groups:  237\n",
      "number of groups:  238\n",
      "number of groups:  239\n",
      "number of groups:  240\n",
      "number of groups:  241\n",
      "number of groups:  242\n",
      "number of groups:  243\n",
      "number of groups:  244\n",
      "number of groups:  245\n",
      "number of groups:  246\n",
      "number of groups:  247\n",
      "number of groups:  248\n",
      "number of groups:  249\n",
      "number of groups:  250\n",
      "number of groups:  251\n",
      "number of groups:  252\n",
      "number of groups:  253\n",
      "number of groups:  254\n",
      "number of groups:  255\n",
      "number of groups:  256\n",
      "number of groups:  257\n",
      "number of groups:  258\n",
      "number of groups:  259\n",
      "number of groups:  260\n",
      "number of groups:  261\n",
      "number of groups:  262\n",
      "number of groups:  263\n",
      "number of groups:  264\n",
      "number of groups:  265\n",
      "number of groups:  266\n",
      "number of groups:  267\n",
      "number of groups:  268\n",
      "number of groups:  269\n",
      "number of groups:  270\n",
      "number of groups:  271\n",
      "number of groups:  272\n",
      "number of groups:  273\n",
      "number of groups:  274\n",
      "number of groups:  275\n",
      "number of groups:  276\n",
      "number of groups:  277\n",
      "number of groups:  278\n",
      "number of groups:  279\n",
      "number of groups:  280\n",
      "number of groups:  281\n",
      "number of groups:  282\n",
      "number of groups:  283\n",
      "number of groups:  284\n",
      "number of groups:  285\n",
      "number of groups:  286\n",
      "number of groups:  287\n",
      "number of groups:  288\n",
      "number of groups:  289\n",
      "number of groups:  290\n",
      "number of groups:  291\n",
      "number of groups:  292\n",
      "number of groups:  293\n",
      "number of groups:  294\n",
      "number of groups:  295\n",
      "number of groups:  296\n",
      "{41: [41], 284: [33, 32, 14, 26, 23, 27, 0, 40, 17, 39, 7, 28, 49, 4, 35, 24, 11, 20, 6, 38, 8, 13, 47, 2, 29, 3, 30, 37, 34, 9, 25, 1, 45, 12, 42, 36, 46, 19, 21, 48, 10, 44, 31, 43, 16, 5, 18, 22, 15], 296: [143, 120, 140, 145, 141, 144, 139, 112, 124, 147, 110, 137, 116, 103, 132, 128, 104, 138, 127, 149, 70, 126, 123, 111, 146, 102, 86, 52, 75, 65, 58, 50, 97, 74, 71, 91, 63, 78, 61, 76, 73, 54, 84, 66, 56, 51, 85, 133, 83, 89, 53, 95, 88, 99, 96, 94, 55, 92, 82, 90, 81, 80, 69, 67, 79, 64, 77, 148, 136, 100, 115, 59, 134, 72, 142, 101, 121, 113, 87, 68, 119, 129, 125, 130, 107, 122, 105, 135, 108, 118, 93, 57, 98, 60, 62, 114, 109, 106, 131, 117]}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Adjust_Rand_Index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15796/1910749130.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mARI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdjust_Rand_Index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Adjusted Rand Index: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mARI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Adjust_Rand_Index' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    xarray, ylist = load_data('iris.data')\n",
    "    start = time.time()\n",
    "    k = 3\n",
    "    dists = Distances(Xarray)\n",
    "    print(dists)\n",
    "    group_dict = clustersing(Xarray, k, dists)\n",
    "    end = time.time()\n",
    "    print(group_dict)\n",
    "    ARI = Adjust_Rand_Index(group_dict, Ylist, k)\n",
    "    print('Adjusted Rand Index: ', ARI)\n",
    "    print('Time: ', end-start)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7af97de8e7140f0a6952c0d53c4bf364c20846b0eea35a1dd78e46eaf795670"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
